<html>
<head>
	<title>Guitar Trainer</title>
	<style>
		canvas{
			border: solid black 1px;
		}
	</style>
</head>
<body>
<div id="debug"></div>
<canvas id="canvas" width="1250" height="700" style="display: block;"></canvas>
</body>
<script type="text/javascript" src="jquery-1.8.0.min.js"></script>
<script type="text/javascript">
	function debug(msg){
		$("#debug").html(msg);
	}

	function micSuccess(stream){
		sourceNode = context.createMediaStreamSource(stream);
		console.log("Mic connection");
		sourceNode.connect(hp);
		hp.connect(lp);
		lp.connect(analyser);

		analyser.connect(javascriptNode);

		sourceNode.connect(context.destination);
	}


	function micError(){

	}

	function connectMic(){
		navigator.webkitGetUserMedia({audio: true}, micSuccess, micError);
	}

	function setupAudioNodes() {

		// setup a javascript node
		javascriptNode = context.createJavaScriptNode(2048, 1, 1);
		// connect to destination, else it isn't called
		javascriptNode.connect(context.destination);


		// setup a analyzer
		analyser = context.createAnalyser();
		analyser.smoothingTimeConstant = 0.3;
		analyser.fftSize = 2048;

		// create a buffer source node
		connectMic();
	}

	// log if an error occurs
	function onError(e) {
		console.log(e);
	}

	function drawSpectrum(array, lowFreq, highFreq){
		var i, len = array.length;
		var lowIndex = Math.floor(lowFreq*analyser.fftSize/context.sampleRate);
		var highIndex = Math.floor(highFreq*analyser.fftSize/context.sampleRate);
		var legendInterval = (highIndex-lowIndex)/10;
		var spikeWidth = ctx.canvas.width/(highIndex-lowIndex);
		//console.log(context.sampleRate + " - " + analyser.fftSize);
		// 44100 - 2048
		for (i=lowIndex; i<highIndex; i++){
			var x = i * spikeWidth;
			var value = array[i];
			ctx.fillRect(x, 700-value, spikeWidth, 700);
			var freq = i*context.sampleRate/analyser.fftSize;
			if( (i%(Math.floor(legendInterval)) == 0) || (i == highIndex) ){
				ctx.fillText(Math.floor(freq), x, 350);
			}
		}
	};

	// create the audio context (chrome only for now)
	var context = new webkitAudioContext();
	var lp = context.createBiquadFilter();
	lp.type = lp.LOWPASS;
	lp.frequency = 8000;
	lp.Q = 0.1;

	var hp = context.createBiquadFilter();
	hp.type = hp.HIGHPASS;
	hp.frequency = 20;
	hp.Q = 0.1;

	var audioBuffer;
	var sourceNode;
	var analyser;
	var javascriptNode;

	var maxAmplitudes = [];

	// get the context from the canvas to draw on
	var ctx = $("#canvas").get()[0].getContext("2d");

	// create a gradient for the fill. Note the strange
	// offset, since the gradient is calculated based on
	// the canvas, not the specific element we draw
	var gradient = ctx.createLinearGradient(0,0,0,300);
	gradient.addColorStop(1,'#5588ff');
	gradient.addColorStop(0.75,'#ff0000');
	gradient.addColorStop(0.25,'#ffff00');
	gradient.addColorStop(0,'#ffffff');

	// load the sound
	setupAudioNodes();

		// when the javascript node is called
	// we use information from the analyzer node
	// to draw the volume
	javascriptNode.onaudioprocess = function() {
		// get the average for the first channel
		var array =  new Uint8Array(analyser.frequencyBinCount);
		analyser.getByteFrequencyData(array);

		// clear the current state
		ctx.clearRect(0, 0, ctx.canvas.width, 700);

		// set the fill style
		ctx.fillStyle=gradient;
		drawSpectrum(array, 20, 1400);

	}

</script>
</html>